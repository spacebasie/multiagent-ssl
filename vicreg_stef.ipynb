{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spacebasie/multiagent-ssl/blob/main/vicreg_stef.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "UuIJykqTxcYF",
        "outputId": "916b20d4-7f2b-4e16-820d-16ab22d0ab28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightly\n",
            "  Downloading lightly-1.5.21-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from lightly) (2025.6.15)\n",
            "Collecting hydra-core>=1.0.0 (from lightly)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting lightly_utils~=0.0.0 (from lightly)\n",
            "  Downloading lightly_utils-0.0.2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.11/dist-packages (from lightly) (2.0.2)\n",
            "Requirement already satisfied: python_dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from lightly) (2.9.0.post0)\n",
            "Requirement already satisfied: requests>=2.27.0 in /usr/local/lib/python3.11/dist-packages (from lightly) (2.32.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from lightly) (1.17.0)\n",
            "Requirement already satisfied: tqdm>=4.44 in /usr/local/lib/python3.11/dist-packages (from lightly) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from lightly) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from lightly) (0.21.0+cu124)\n",
            "Requirement already satisfied: pydantic>=1.10.5 in /usr/local/lib/python3.11/dist-packages (from lightly) (2.11.7)\n",
            "Collecting pytorch_lightning>=1.0.4 (from lightly)\n",
            "  Downloading pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from lightly) (2.4.0)\n",
            "Collecting aenum>=3.1.11 (from lightly)\n",
            "  Downloading aenum-3.1.16-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.0.0->lightly) (2.3.0)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.0.0->lightly) (4.9.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.0.0->lightly) (24.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from lightly_utils~=0.0.0->lightly) (11.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.5->lightly) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.5->lightly) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.5->lightly) (4.14.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.5->lightly) (0.4.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning>=1.0.4->lightly) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (2025.3.2)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning>=1.0.4->lightly)\n",
            "  Downloading torchmetrics-1.7.3-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch_lightning>=1.0.4->lightly)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.0->lightly) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.0->lightly) (3.10)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->lightly)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->lightly)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->lightly)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->lightly)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->lightly)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->lightly)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->lightly)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->lightly)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->lightly)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->lightly)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->lightly) (1.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (3.11.15)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning>=1.0.4->lightly) (75.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->lightly) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (1.20.1)\n",
            "Downloading lightly-1.5.21-py3-none-any.whl (855 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m855.8/855.8 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aenum-3.1.16-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.6/165.6 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightly_utils-0.0.2-py3-none-any.whl (6.4 kB)\n",
            "Downloading pytorch_lightning-2.5.2-py3-none-any.whl (825 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m128.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading torchmetrics-1.7.3-py3-none-any.whl (962 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m962.6/962.6 kB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: aenum, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, lightly_utils, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, nvidia-cusolver-cu12, torchmetrics, pytorch_lightning, lightly\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed aenum-3.1.16 hydra-core-1.3.2 lightly-1.5.21 lightly_utils-0.0.2 lightning-utilities-0.14.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch_lightning-2.5.2 torchmetrics-1.7.3\n"
          ]
        }
      ],
      "source": [
        "# Install lightly\n",
        "!pip install lightly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRGKZYmZyjKM"
      },
      "source": [
        "**Import dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qXU9_uq9NtGR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2da54c5-8161-4aa8-fefd-d34d7688ffc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# This example requires the following dependencies to be installed:\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "from lightly.loss import VICRegLoss\n",
        "from lightly.models.modules.heads import VICRegProjectionHead\n",
        "from lightly.transforms.vicreg_transform import VICRegTransform\n",
        "import torch.nn.functional as F\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_H4YvDRyrtE"
      },
      "source": [
        "Define the VICReg model and its forward pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RR4WVa8SyANf"
      },
      "outputs": [],
      "source": [
        "# --- 1. Model Definition ---\n",
        "class VICReg(nn.Module):\n",
        "    def __init__(self, backbone, proj_input_dim=512):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.projection_head = VICRegProjectionHead(\n",
        "            input_dim=proj_input_dim,\n",
        "            hidden_dim=2048,\n",
        "            output_dim=2048,\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = x.flatten(start_dim=1)\n",
        "        z = self.projection_head(x)\n",
        "        return z\n",
        "\n",
        "    def forward_backbone(self, x):\n",
        "        x = self.backbone(x)\n",
        "        return x.flatten(start_dim=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 0. VICReg Loss Definition (New Block) ---\n",
        "class VICRegLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    VICReg Loss Function.\n",
        "    Args:\n",
        "        lambda_ (float): Coefficient for the invariance term.\n",
        "        mu (float): Coefficient for the variance term.\n",
        "        nu (float): Coefficient for the covariance term.\n",
        "        epsilon (float): Small value for numerical stability in variance calculation.\n",
        "    \"\"\"\n",
        "    def __init__(self, lambda_=25.0, mu=25.0, nu=1.0, epsilon=1e-4):\n",
        "        super().__init__()\n",
        "        self.lambda_ = lambda_\n",
        "        self.mu = mu\n",
        "        self.nu = nu\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def forward(self, z_a, z_b):\n",
        "        # Invariance term (Mean Squared Error)\n",
        "        # Encourages the representations of two views of the same image to be similar.\n",
        "        sim_loss = F.mse_loss(z_a, z_b)\n",
        "\n",
        "        # Variance term\n",
        "        # Encourages the variance of each dimension in the representation batch to be close to 1.\n",
        "        std_z_a = torch.sqrt(z_a.var(dim=0) + self.epsilon)\n",
        "        std_z_b = torch.sqrt(z_b.var(dim=0) + self.epsilon)\n",
        "        std_loss = torch.mean(F.relu(1 - std_z_a)) + torch.mean(F.relu(1 - std_z_b))\n",
        "\n",
        "        # Covariance term\n",
        "        # Encourages the off-diagonal elements of the covariance matrix to be zero,\n",
        "        # decorrelating the dimensions of the representation.\n",
        "        z_a_norm = z_a - z_a.mean(dim=0)\n",
        "        z_b_norm = z_b - z_b.mean(dim=0)\n",
        "        N, D = z_a.shape\n",
        "        cov_z_a = (z_a_norm.T @ z_a_norm) / (N - 1)\n",
        "        cov_z_b = (z_b_norm.T @ z_b_norm) / (N - 1)\n",
        "\n",
        "        # Zero out the diagonal elements to only consider off-diagonal covariance\n",
        "        off_diag_mask = ~torch.eye(D, device=z_a.device).bool()\n",
        "        cov_loss = (cov_z_a[off_diag_mask].pow_(2).sum() / D) + \\\n",
        "                   (cov_z_b[off_diag_mask].pow_(2).sum() / D)\n",
        "\n",
        "        # Combine the three terms with their coefficients\n",
        "        loss = (self.lambda_ * sim_loss) + (self.mu * std_loss) + (self.nu * cov_loss)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "U-h9fMSfCSoZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgooj9CkywTj"
      },
      "source": [
        "Initialize the resnet, backbone and model as well as the data loader and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TdNJQsPzyEUe"
      },
      "outputs": [],
      "source": [
        "# --- 2. Pretraining ---\n",
        "def vicreg_pretraining(model, dataloader, epochs, device, lambda_, mu, nu):\n",
        "    \"\"\"Runs the VICReg self-supervised pre-training with specified hyperparameters.\"\"\"\n",
        "    # Pass hyperparameters to the loss function\n",
        "    criterion = VICRegLoss(lambda_=lambda_, mu=mu, nu=nu)\n",
        "    # Using a safer learning rate to prevent 'nan' loss instability\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
        "    model.to(device)\n",
        "\n",
        "    epoch_losses = []\n",
        "    print(f\"Starting VICReg Pre-training for lambda={lambda_}, mu={mu}, nu={nu}\")\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        # Using the original, robust batch unpacking method\n",
        "        for batch_idx, batch in enumerate(dataloader):\n",
        "            # Unpack the two augmented views from the batch tuple\n",
        "            x0, x1 = batch[0]\n",
        "            x0 = x0.to(device)\n",
        "            x1 = x1.to(device)\n",
        "\n",
        "            z0 = model(x0)\n",
        "            z1 = model(x1)\n",
        "\n",
        "            loss = criterion(z0, z1)\n",
        "\n",
        "            # Safety check for numerical instability\n",
        "            if torch.isnan(loss):\n",
        "                print(f\"Loss became NaN at epoch {epoch}, batch {batch_idx}. Stopping training.\")\n",
        "                print(\"This is likely caused by a learning rate that is too high. Try reducing it further.\")\n",
        "                # Return early if loss is NaN\n",
        "                return\n",
        "\n",
        "            total_loss += loss.detach()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        epoch_losses.append(avg_loss.cpu().item())\n",
        "        print(f\"Epoch: {epoch:02}, Loss: {avg_loss:.5f}\")\n",
        "\n",
        "    print(\"Pre-training Finished.\")\n",
        "\n",
        "    # Plotting the results (optional, can be adapted for multiple runs)\n",
        "    # You might want to save plots with unique names for each hyperparameter set\n",
        "    if epoch_losses:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(epoch_losses, marker='o', linestyle='-')\n",
        "        plt.title(f'VICReg Training Loss (λ={lambda_}, μ={mu}, ν={nu})')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Average Loss')\n",
        "        plt.grid(True)\n",
        "        plt.savefig(f\"vicreg_loss_l{lambda_}_m{mu}.png\")\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "P2nLCTLC48Jc"
      },
      "outputs": [],
      "source": [
        "# --- 3. Linear Evaluation ---\n",
        "def linear_evaluation(model, proj_output_dim, train_loader, test_loader, epochs, device):\n",
        "    \"\"\"Runs the linear evaluation on the frozen backbone.\"\"\"\n",
        "    print(\"\\nStarting Linear Evaluation\")\n",
        "\n",
        "    # Freeze the backbone\n",
        "    for param in model.backbone.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # The input dimension to the classifier must match the backbone's output dimension\n",
        "    classifier = nn.Linear(proj_output_dim, 10).to(device) # CIFAR-10 has 10 classes\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
        "\n",
        "    # Training the linear classifier\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                representations = model.forward_backbone(images)\n",
        "\n",
        "            predictions = classifier(representations)\n",
        "            loss = criterion(predictions, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"Classifier Training Epoch: {epoch:02}, Loss: {avg_loss:.5f}\")\n",
        "\n",
        "    # Evaluate the classifier\n",
        "    print(\"\\nEvaluating on Test Set...\")\n",
        "    classifier.eval()\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            representations = model.forward_backbone(images)\n",
        "            predictions = classifier(representations)\n",
        "            _, predicted = torch.max(predictions.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Final Test Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYS-4aqo_bF4"
      },
      "source": [
        "**Main Execution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c65a735"
      },
      "source": [
        "Define the kNN evaluation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2542482b"
      },
      "source": [
        "# --- 4. kNN Evaluation ---\n",
        "def knn_evaluation(model, train_loader, test_loader, device, k=200, temperature=0.1):\n",
        "    \"\"\"Runs the kNN evaluation on the frozen backbone.\"\"\"\n",
        "    print(\"\\nStarting kNN Evaluation\")\n",
        "\n",
        "    # Freeze the model backbone\n",
        "    model.eval()\n",
        "    for param in model.backbone.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Gather features from the training set\n",
        "    train_features = []\n",
        "    train_labels = []\n",
        "    print(\"Gathering training features for kNN...\")\n",
        "    with torch.no_grad():\n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(device)\n",
        "            features = model.forward_backbone(images)\n",
        "            train_features.append(features)\n",
        "            train_labels.append(labels)\n",
        "\n",
        "    train_features = torch.cat(train_features, dim=0)\n",
        "    train_labels = torch.cat(train_labels, dim=0).to(device) # Move train_labels to the specified device\n",
        "\n",
        "    # Normalize features\n",
        "    train_features = F.normalize(train_features, dim=1)\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    print(\"Evaluating on test set using kNN...\")\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            test_features = model.forward_backbone(images)\n",
        "            test_features = F.normalize(test_features, dim=1)\n",
        "\n",
        "            # Compute similarity matrix\n",
        "            similarity_matrix = torch.matmul(test_features, train_features.T) / temperature\n",
        "\n",
        "            # Get top-k neighbors\n",
        "            _, indices = similarity_matrix.topk(k, dim=1, largest=True, sorted=True)\n",
        "\n",
        "            # Get labels of top-k neighbors\n",
        "            k_neighbor_labels = train_labels[indices]\n",
        "\n",
        "            # Predict the class based on majority vote\n",
        "            # For each test sample, count the occurrences of each class among its k neighbors\n",
        "            predictions = torch.mode(k_neighbor_labels, dim=1).values\n",
        "            correct += (predictions == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Final kNN Test Accuracy: {accuracy:.2f}%\")\n",
        "    return accuracy"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4430575"
      },
      "source": [
        "Update the main execution block to include kNN evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "57f4b45e",
        "outputId": "3f5ffd91-02bc-4116-95f7-e35793e03061"
      },
      "source": [
        "# --- Main Execution ---\n",
        "if __name__ == '__main__':\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    PRETRAIN_EPOCHS = 100\n",
        "    EVAL_EPOCHS = 50\n",
        "    BATCH_SIZE = 256\n",
        "\n",
        "    # --- Hyperparameter Grid Search ---\n",
        "    # Define the grid of hyperparameters to search.\n",
        "    # The paper suggests lambda = mu = 25 and nu = 1 as a good starting point.\n",
        "    lambda_values = [30]\n",
        "    mu_values = [30]\n",
        "    nu_value = 1.0  # Fixed as per the paper and your request\n",
        "\n",
        "    results = []\n",
        "    print(\"Starting Hyperparameter Grid Search for VICReg...\")\n",
        "\n",
        "    # --- Data Loading (define it once outside the loop) ---\n",
        "    transform_vicreg = VICRegTransform(input_size=32)\n",
        "    pretrain_dataset = torchvision.datasets.CIFAR10(\n",
        "        \"datasets/cifar10\", download=True, transform=transform_vicreg\n",
        "    )\n",
        "    pretrain_dataloader = torch.utils.data.DataLoader(\n",
        "        pretrain_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=2\n",
        "    )\n",
        "    transform_eval = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    ])\n",
        "    train_dataset_eval = torchvision.datasets.CIFAR10(\n",
        "        \"datasets/cifar10\", download=True, train=True, transform=transform_eval\n",
        "    )\n",
        "    test_dataset_eval = torchvision.datasets.CIFAR10(\n",
        "        \"datasets/cifar10\", download=True, train=False, transform=transform_eval\n",
        "    )\n",
        "    train_loader_eval = torch.utils.data.DataLoader(\n",
        "        train_dataset_eval, batch_size=BATCH_SIZE, shuffle=True, num_workers=2\n",
        "    )\n",
        "    test_loader_eval = torch.utils.data.DataLoader(\n",
        "        test_dataset_eval, batch_size=BATCH_SIZE, shuffle=False, num_workers=2\n",
        "    )\n",
        "\n",
        "    for lambda_ in lambda_values:\n",
        "        for mu in mu_values:\n",
        "            print(\"-\" * 60)\n",
        "            print(f\"Testing hyperparameters: lambda={lambda_}, mu={mu}, nu={nu_value}\")\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "            # --- Model Initialization ---\n",
        "            # Re-initialize the model for each run to ensure a fair, independent trial\n",
        "            BACKBONE = torchvision.models.resnet18()\n",
        "            PROJ_INPUT_DIM = 512 # ResNet-18 outputs 512 features\n",
        "            backbone = nn.Sequential(*list(BACKBONE.children())[:-1])\n",
        "            model = VICReg(backbone, proj_input_dim=PROJ_INPUT_DIM).to(device)\n",
        "\n",
        "            # --- Training ---\n",
        "            # Pass the current hyperparameters to the pretraining function\n",
        "            vicreg_pretraining(model, pretrain_dataloader, PRETRAIN_EPOCHS, device, lambda_=lambda_, mu=mu, nu=nu_value)\n",
        "\n",
        "            # --- Linear Evaluation ---\n",
        "            linear_acc = linear_evaluation(model, proj_output_dim=PROJ_INPUT_DIM, train_loader=train_loader_eval, test_loader=test_loader_eval, epochs=EVAL_EPOCHS, device=device)\n",
        "\n",
        "            # --- kNN evaluation ---\n",
        "            knn_acc = knn_evaluation(model, train_loader_eval, test_loader_eval, device)\n",
        "\n",
        "            # Store results for this run\n",
        "            results.append({\n",
        "                'lambda': lambda_,\n",
        "                'mu': mu,\n",
        "                'nu': nu_value,\n",
        "                'linear_accuracy': linear_acc,\n",
        "                'knn_accuracy': knn_acc\n",
        "            })\n",
        "\n",
        "    # --- Print Final Results Summary ---\n",
        "    print(\"\\n\\n\" + \"=\" * 60)\n",
        "    print(\"Hyperparameter Tuning Grid Search Results\")\n",
        "    print(\"=\" * 60)\n",
        "    # Sort results by the metric you care about most (e.g., linear accuracy)\n",
        "    sorted_results = sorted(results, key=lambda x: x['linear_accuracy'], reverse=True)\n",
        "    for res in sorted_results:\n",
        "        print(f\"λ={res['lambda']:<4}, μ={res['mu']:<4}, ν={res['nu']} -> \"\n",
        "              f\"Linear Accuracy: {res['linear_accuracy']:.2f}%, \"\n",
        "              f\"kNN Accuracy: {res['knn_accuracy']:.2f}%\")\n",
        "\n",
        "    best_run = sorted_results[0]\n",
        "    print(\"\\nBest Performing Hyperparameters (by Linear Accuracy):\")\n",
        "    print(f\"λ={best_run['lambda']}, μ={best_run['mu']}, ν={best_run['nu']} with \"\n",
        "          f\"Linear Accuracy: {best_run['linear_accuracy']:.2f}% and \"\n",
        "          f\"kNN Accuracy: {best_run['knn_accuracy']:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Hyperparameter Grid Search for VICReg...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "Testing hyperparameters: lambda=30, mu=30, nu=1.0\n",
            "------------------------------------------------------------\n",
            "Starting VICReg Pre-training for lambda=30, mu=30, nu=1.0\n",
            "Epoch: 00, Loss: 46.05739\n",
            "Epoch: 01, Loss: 45.13380\n",
            "Epoch: 02, Loss: 44.65610\n",
            "Epoch: 03, Loss: 44.29099\n",
            "Epoch: 04, Loss: 44.02333\n",
            "Epoch: 05, Loss: 43.75507\n",
            "Epoch: 06, Loss: 43.53495\n",
            "Epoch: 07, Loss: 43.34589\n",
            "Epoch: 08, Loss: 43.22565\n",
            "Epoch: 09, Loss: 43.03850\n",
            "Epoch: 10, Loss: 42.90893\n",
            "Epoch: 11, Loss: 42.76710\n",
            "Epoch: 12, Loss: 42.64973\n",
            "Epoch: 13, Loss: 42.57952\n",
            "Epoch: 14, Loss: 42.48263\n",
            "Epoch: 15, Loss: 42.38155\n",
            "Epoch: 16, Loss: 42.31141\n",
            "Epoch: 17, Loss: 42.20211\n",
            "Epoch: 18, Loss: 42.16481\n",
            "Epoch: 19, Loss: 42.05097\n",
            "Epoch: 20, Loss: 42.04647\n",
            "Epoch: 21, Loss: 41.93783\n",
            "Epoch: 22, Loss: 41.90476\n",
            "Epoch: 23, Loss: 41.83053\n",
            "Epoch: 24, Loss: 41.72695\n",
            "Epoch: 25, Loss: 41.76415\n",
            "Epoch: 26, Loss: 41.61401\n",
            "Epoch: 27, Loss: 41.61245\n",
            "Epoch: 28, Loss: 41.56062\n",
            "Epoch: 29, Loss: 41.48650\n",
            "Epoch: 30, Loss: 41.44143\n",
            "Epoch: 31, Loss: 41.41798\n",
            "Epoch: 32, Loss: 41.33843\n",
            "Epoch: 33, Loss: 41.33453\n",
            "Epoch: 34, Loss: 41.30323\n",
            "Epoch: 35, Loss: 41.28840\n",
            "Epoch: 36, Loss: 41.24596\n",
            "Epoch: 37, Loss: 41.18516\n",
            "Epoch: 38, Loss: 41.09245\n",
            "Epoch: 39, Loss: 41.10771\n",
            "Epoch: 40, Loss: 41.05305\n",
            "Epoch: 41, Loss: 41.03151\n",
            "Epoch: 42, Loss: 41.01473\n",
            "Epoch: 43, Loss: 41.00407\n",
            "Epoch: 44, Loss: 40.95209\n",
            "Epoch: 45, Loss: 40.89116\n",
            "Epoch: 46, Loss: 40.83846\n",
            "Epoch: 47, Loss: 40.82220\n",
            "Epoch: 48, Loss: 40.81638\n",
            "Epoch: 49, Loss: 40.78147\n",
            "Epoch: 50, Loss: 40.71557\n",
            "Epoch: 51, Loss: 40.68713\n",
            "Epoch: 52, Loss: 40.68241\n",
            "Epoch: 53, Loss: 40.67635\n",
            "Epoch: 54, Loss: 40.58408\n",
            "Epoch: 55, Loss: 40.54553\n",
            "Epoch: 56, Loss: 40.56126\n",
            "Epoch: 57, Loss: 40.58514\n",
            "Epoch: 58, Loss: 40.52559\n",
            "Epoch: 59, Loss: 40.45130\n",
            "Epoch: 60, Loss: 40.47964\n",
            "Epoch: 61, Loss: 40.43439\n",
            "Epoch: 62, Loss: 40.41575\n",
            "Epoch: 63, Loss: 40.38083\n",
            "Epoch: 64, Loss: 40.34392\n",
            "Epoch: 65, Loss: 40.34369\n",
            "Epoch: 66, Loss: 40.35559\n",
            "Epoch: 67, Loss: 40.29818\n",
            "Epoch: 68, Loss: 40.31685\n",
            "Epoch: 69, Loss: 40.27014\n",
            "Epoch: 70, Loss: 40.24538\n",
            "Epoch: 71, Loss: 40.24538\n",
            "Epoch: 72, Loss: 40.21032\n",
            "Epoch: 73, Loss: 40.13208\n",
            "Epoch: 74, Loss: 40.18613\n",
            "Epoch: 75, Loss: 40.12305\n",
            "Epoch: 76, Loss: 40.16277\n",
            "Epoch: 77, Loss: 40.08459\n",
            "Epoch: 78, Loss: 40.08447\n",
            "Epoch: 79, Loss: 40.08744\n",
            "Epoch: 80, Loss: 40.03628\n",
            "Epoch: 81, Loss: 39.98445\n",
            "Epoch: 82, Loss: 40.01943\n",
            "Epoch: 83, Loss: 39.95515\n",
            "Epoch: 84, Loss: 39.95497\n",
            "Epoch: 85, Loss: 39.94443\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMZ3E2901T9XeUMAk2RjEoz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}